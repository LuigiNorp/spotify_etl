{
    "sourceFile": "docker/docker-compose.yaml",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1646290018704,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1646290088267,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n services:\n   postgres:\n     image: postgres:13\n     env_file:\n-      - ./docker/postgres/postgres.env\n+      - ./postgres/postgres.env\n     volumes:\n       - postgres-db-volume:/var/lib/postgresql/data\n     healthcheck:\n       test: [\"CMD\", \"pg_isready\", \"-U\", \"airflow\"]\n@@ -90,9 +90,9 @@\n       dockerfile: Dockerfile\n       context: docker/pgadmin\n     restart: unless-stopped\n     env_file:\n-      - ./docker/pgadmin/pgadmin.env\n+      - ./pgadmin/pgadmin.env\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n"
                },
                {
                    "date": 1646290259888,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n services:\n   postgres:\n     image: postgres:13\n     env_file:\n-      - ./postgres/postgres.env\n+      - docker/postgres/postgres.env\n     volumes:\n       - postgres-db-volume:/var/lib/postgresql/data\n     healthcheck:\n       test: [\"CMD\", \"pg_isready\", \"-U\", \"airflow\"]\n@@ -90,9 +90,9 @@\n       dockerfile: Dockerfile\n       context: docker/pgadmin\n     restart: unless-stopped\n     env_file:\n-      - ./pgadmin/pgadmin.env\n+      - docker/pgadmin/pgadmin.env\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n"
                },
                {
                    "date": 1646290307613,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n services:\n   postgres:\n     image: postgres:13\n     env_file:\n-      - docker/postgres/postgres.env\n+      - postgres/postgres.env\n     volumes:\n       - postgres-db-volume:/var/lib/postgresql/data\n     healthcheck:\n       test: [\"CMD\", \"pg_isready\", \"-U\", \"airflow\"]\n@@ -90,9 +90,9 @@\n       dockerfile: Dockerfile\n       context: docker/pgadmin\n     restart: unless-stopped\n     env_file:\n-      - docker/pgadmin/pgadmin.env\n+      - pgadmin/pgadmin.env\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n"
                },
                {
                    "date": 1646290414722,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -87,9 +87,9 @@\n   pgadmin:\n     image: dpage/pgadmin4:4.18\n     build:\n       dockerfile: Dockerfile\n-      context: docker/pgadmin\n+      context: pgadmin\n     restart: unless-stopped\n     env_file:\n       - pgadmin/pgadmin.env\n     ports:\n"
                },
                {
                    "date": 1646291030154,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,20 +95,11 @@\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n-#    links:\n-#      - \"db:pgsql-server\"\n+    links:\n+      - \"db:pgsql-server\"\n \n-  web:\n-    build: .\n-    command: python manage.py runserver 0.0.0.0:8000\n-    volumes:\n-      - .:/code\n-    ports:\n-      - \"8000:8000\"\n-    depends_on:\n-      - db\n \n   redis:\n     image: redis:latest\n     expose:\n@@ -289,4 +280,6 @@\n     depends_on:\n       <<: *airflow-common-depends-on\n       airflow-init:\n         condition: service_completed_successfully\n+volumes:\n+  postgres-db-volume:\n\\ No newline at end of file\n"
                },
                {
                    "date": 1646291188714,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,12 +95,9 @@\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n-    links:\n-      - \"db:pgsql-server\"\n \n-\n   redis:\n     image: redis:latest\n     expose:\n       - 6379\n"
                },
                {
                    "date": 1646327949797,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,21 +47,23 @@\n   image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.2.4}\n   # build: .\n   environment:\n     &airflow-common-env\n-    AIRFLOW__CORE__EXECUTOR: CeleryExecutor\n-    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow\n-    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow\n-    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0\n-    AIRFLOW__CORE__FERNET_KEY: ''\n-    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'\n-    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'\n-    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'\n+#    AIRFLOW__CORE__EXECUTOR: CeleryExecutor\n+#    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow\n+#    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow\n+#    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0\n+#    AIRFLOW__CORE__FERNET_KEY: ''\n+#    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'\n+#    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'\n+#    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'\n     _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}\n+  env_file:\n+  - airflow/airflow.env\n   volumes:\n-    - ./airflow/dags:/opt/airflow/dags\n-    - ./airflow/logs:/opt/airflow/logs\n-    - ./airflow/plugins:/opt/airflow/plugins\n+    - ./.devcontainer/airflow/dags:/opt/airflow/dags\n+    - ./.devcontainer/airflow/logs:/opt/airflow/logs\n+    - ./.devcontainer/airflow/plugins:/opt/airflow/plugins\n   user: \"${AIRFLOW_UID:-50000}:0\"\n   depends_on:\n     &airflow-common-depends-on\n     redis:\n@@ -72,9 +74,9 @@\n services:\n   postgres:\n     image: postgres:13\n     env_file:\n-      - postgres/postgres.env\n+      - .devcontainer/postgres/postgres.env\n     volumes:\n       - postgres-db-volume:/var/lib/postgresql/data\n     healthcheck:\n       test: [\"CMD\", \"pg_isready\", \"-U\", \"airflow\"]\n@@ -90,9 +92,9 @@\n       dockerfile: Dockerfile\n       context: pgadmin\n     restart: unless-stopped\n     env_file:\n-      - pgadmin/pgadmin.env\n+      - .devcontainer/pgadmin/pgadmin.env\n     ports:\n       - \"8484:80\"\n     volumes:\n       - ./pgadmin-data:/var/lib/pgadmin\n"
                }
            ],
            "date": 1646290018704,
            "name": "Commit-0",
            "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\n# Basic Airflow cluster configuration for CeleryExecutor with Redis and PostgreSQL.\n#\n# WARNING: This configuration is for local development. Do not use it in a production deployment.\n#\n# This configuration supports basic configuration using environment variables or an .env file\n# The following variables are supported:\n#config\n# AIRFLOW_IMAGE_NAME           - Docker image name used to run Airflow.\n#                                Default: apache/airflow:2.2.4\n# AIRFLOW_UID                  - User ID in Airflow containers\n#                                Default: 50000\n# Those configurations are useful mostly in case of standalone testing/running Airflow in test/try-out mode\n#\n# _AIRFLOW_WWW_USER_USERNAME   - Username for the administrator account (if requested).\n#                                Default: airflow\n# _AIRFLOW_WWW_USER_PASSWORD   - Password for the administrator account (if requested).\n#                                Default: airflow\n# _PIP_ADDITIONAL_REQUIREMENTS - Additional PIP requirements to add when starting all containers.\n#                                Default: ''\n#\n# Feel free to modify this file to suit your needs.\n---\nversion: '3'\nx-airflow-common:\n  &airflow-common\n  # In order to add custom dependencies or upgrade provider packages you can use your extended image.\n  # Comment the image line, place your Dockerfile in the directory where you placed the docker-compose.yaml\n  # and uncomment the \"build\" line below, Then run `docker-compose build` to build the images.\n  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.2.4}\n  # build: .\n  environment:\n    &airflow-common-env\n    AIRFLOW__CORE__EXECUTOR: CeleryExecutor\n    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow\n    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow\n    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0\n    AIRFLOW__CORE__FERNET_KEY: ''\n    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'\n    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'\n    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'\n    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}\n  volumes:\n    - ./airflow/dags:/opt/airflow/dags\n    - ./airflow/logs:/opt/airflow/logs\n    - ./airflow/plugins:/opt/airflow/plugins\n  user: \"${AIRFLOW_UID:-50000}:0\"\n  depends_on:\n    &airflow-common-depends-on\n    redis:\n      condition: service_healthy\n    postgres:\n      condition: service_healthy\n\nservices:\n  postgres:\n    image: postgres:13\n    env_file:\n      - ./docker/postgres/postgres.env\n    volumes:\n      - postgres-db-volume:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD\", \"pg_isready\", \"-U\", \"airflow\"]\n      interval: 5s\n      retries: 5\n    restart: always\n    ports:\n     - 5432:5432\n\n  pgadmin:\n    image: dpage/pgadmin4:4.18\n    build:\n      dockerfile: Dockerfile\n      context: docker/pgadmin\n    restart: unless-stopped\n    env_file:\n      - ./docker/pgadmin/pgadmin.env\n    ports:\n      - \"8484:80\"\n    volumes:\n      - ./pgadmin-data:/var/lib/pgadmin\n#    links:\n#      - \"db:pgsql-server\"\n\n  web:\n    build: .\n    command: python manage.py runserver 0.0.0.0:8000\n    volumes:\n      - .:/code\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      - db\n\n  redis:\n    image: redis:latest\n    expose:\n      - 6379\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 5s\n      timeout: 30s\n      retries: 50\n    restart: always\n\n  airflow-webserver:\n    <<: *airflow-common\n    command: webserver\n    ports:\n      - 8080:8080\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"--fail\", \"http://localhost:8080/health\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    restart: always\n    depends_on:\n      <<: *airflow-common-depends-on\n      airflow-init:\n        condition: service_completed_successfully\n\n  airflow-scheduler:\n    <<: *airflow-common\n    command: scheduler\n    healthcheck:\n      test: [\"CMD-SHELL\", 'airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\"']\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    restart: always\n    depends_on:\n      <<: *airflow-common-depends-on\n      airflow-init:\n        condition: service_completed_successfully\n\n  airflow-worker:\n    <<: *airflow-common\n    command: celery worker\n    healthcheck:\n      test:\n        - \"CMD-SHELL\"\n        - 'celery --app airflow.executors.celery_executor.app inspect ping -d \"celery@$${HOSTNAME}\"'\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    environment:\n      <<: *airflow-common-env\n      # Required to handle warm shutdown of the celery workers properly\n      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation\n      DUMB_INIT_SETSID: \"0\"\n    restart: always\n    depends_on:\n      <<: *airflow-common-depends-on\n      airflow-init:\n        condition: service_completed_successfully\n\n  airflow-triggerer:\n    <<: *airflow-common\n    command: triggerer\n    healthcheck:\n      test: [\"CMD-SHELL\", 'airflow jobs check --job-type TriggererJob --hostname \"$${HOSTNAME}\"']\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    restart: always\n    depends_on:\n      <<: *airflow-common-depends-on\n      airflow-init:\n        condition: service_completed_successfully\n\n  airflow-init:\n    <<: *airflow-common\n    entrypoint: /bin/bash\n    # yamllint disable rule:line-length\n    command:\n      - -c\n      - |\n        function ver() {\n          printf \"%04d%04d%04d%04d\" $${1//./ }\n        }\n        airflow_version=$$(gosu airflow airflow version)\n        airflow_version_comparable=$$(ver $${airflow_version})\n        min_airflow_version=2.2.0\n        min_airflow_version_comparable=$$(ver $${min_airflow_version})\n        if (( airflow_version_comparable < min_airflow_version_comparable )); then\n          echo\n          echo -e \"\\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\\e[0m\"\n          echo \"The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!\"\n          echo\n          exit 1\n        fi\n        if [[ -z \"${AIRFLOW_UID}\" ]]; then\n          echo\n          echo -e \"\\033[1;33mWARNING!!!: AIRFLOW_UID not set!\\e[0m\"\n          echo \"If you are on Linux, you SHOULD follow the instructions below to set \"\n          echo \"AIRFLOW_UID environment variable, otherwise files will be owned by root.\"\n          echo \"For other operating systems you can get rid of the warning with manually created .env file:\"\n          echo \"    See: https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user\"\n          echo\n        fi\n        one_meg=1048576\n        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))\n        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)\n        disk_available=$$(df / | tail -1 | awk '{print $$4}')\n        warning_resources=\"false\"\n        if (( mem_available < 4000 )) ; then\n          echo\n          echo -e \"\\033[1;33mWARNING!!!: Not enough memory available for Docker.\\e[0m\"\n          echo \"At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))\"\n          echo\n          warning_resources=\"true\"\n        fi\n        if (( cpus_available < 2 )); then\n          echo\n          echo -e \"\\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\\e[0m\"\n          echo \"At least 2 CPUs recommended. You have $${cpus_available}\"\n          echo\n          warning_resources=\"true\"\n        fi\n        if (( disk_available < one_meg * 10 )); then\n          echo\n          echo -e \"\\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\\e[0m\"\n          echo \"At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))\"\n          echo\n          warning_resources=\"true\"\n        fi\n        if [[ $${warning_resources} == \"true\" ]]; then\n          echo\n          echo -e \"\\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\\e[0m\"\n          echo \"Please follow the instructions to increase amount of resources available:\"\n          echo \"   https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#before-you-begin\"\n          echo\n        fi\n        mkdir -p /sources/logs /sources/dags /sources/plugins\n        chown -R \"${AIRFLOW_UID}:0\" /sources/{logs,dags,plugins}\n        exec /entrypoint airflow version\n    # yamllint enable rule:line-length\n    environment:\n      <<: *airflow-common-env\n      _AIRFLOW_DB_UPGRADE: 'true'\n      _AIRFLOW_WWW_USER_CREATE: 'true'\n      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}\n      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}\n    user: \"0:0\"\n    volumes:\n      - .:/sources\n\n  airflow-cli:\n    <<: *airflow-common\n    profiles:\n      - debug\n    environment:\n      <<: *airflow-common-env\n      CONNECTION_CHECK_MAX_COUNT: \"0\"\n    # Workaround for entrypoint issue. See: https://github.com/apache/airflow/issues/16252\n    command:\n      - bash\n      - -c\n      - airflow\n\n  flower:\n    <<: *airflow-common\n    command: celery flower\n    ports:\n      - 5555:5555\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"--fail\", \"http://localhost:5555/\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    restart: always\n    depends_on:\n      <<: *airflow-common-depends-on\n      airflow-init:\n        condition: service_completed_successfully\n"
        }
    ]
}